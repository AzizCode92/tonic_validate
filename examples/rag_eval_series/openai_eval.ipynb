{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "from tvalmetrics import RagScoresCalculator\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_COMBINE_ESSAYS = True\n",
    "\n",
    "def get_sorted_essays():\n",
    "    # Sort the files so that they are uploaded in order\n",
    "    combined_essays = os.listdir('combined_essays')\n",
    "    combined_essays.sort(key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
    "    print(\"\\n\".join(combined_essays))\n",
    "    return combined_essays\n",
    "\n",
    "# Iterate through paul_graham_essays folder and upload each file to the assistant\n",
    "# Apparently you can't upload more than 20 items to openai's rag so let's just combine them and upload those\n",
    "def combine_essays(group_num):\n",
    "    if not RUN_COMBINE_ESSAYS:\n",
    "        return\n",
    "    essays = os.listdir('paul_graham_essays')\n",
    "    group_size = math.ceil(len(essays) / group_num)\n",
    "    print(f\"Grouping {len(essays)} files into groups of {group_size} files for a total of {group_num} groups\")\n",
    "\n",
    "\n",
    "    # Create directory for combined essays\n",
    "    if not os.path.exists('combined_essays'):\n",
    "        os.makedirs('combined_essays')\n",
    "    else:\n",
    "        # delete all files in combined_essays\n",
    "        for filename in os.listdir('combined_essays'):\n",
    "            os.remove(f'combined_essays/{filename}')\n",
    "\n",
    "    group_counter = 0\n",
    "    file_counter = 1\n",
    "    curr_file_text = \"\"\n",
    "    for filename in tqdm(essays):\n",
    "        with open('paul_graham_essays/' + filename, 'r') as file:\n",
    "            curr_file_text += file.read().strip() + \"\\n\\n\\n\\n\"\n",
    "            group_counter += 1\n",
    "            if group_counter == group_size:\n",
    "                # Write to file\n",
    "                with open(f'combined_essays/paul_graham_{file_counter}.txt', 'w') as combined_file:\n",
    "                    combined_file.write(curr_file_text)\n",
    "                    file_counter += 1\n",
    "                curr_file_text = \"\"\n",
    "                group_counter = 0\n",
    "    \n",
    "    if curr_file_text.strip():\n",
    "        with open(f'combined_essays/paul_graham_{file_counter}.txt', 'w') as combined_file:\n",
    "            combined_file.write(curr_file_text)\n",
    "    return get_sorted_essays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_response(prompt, assistant):\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "    )\n",
    "    max_tries = 180\n",
    "    try:\n",
    "        while True:\n",
    "            if max_tries == 0:\n",
    "                client.beta.threads.delete(thread.id)\n",
    "                raise Exception(\"Max tries exceeded\")\n",
    "            messages = client.beta.threads.messages.list(\n",
    "                thread_id=thread.id,\n",
    "            )\n",
    "            response_message = messages.data[0].content[0].text.value\n",
    "            if response_message != prompt and response_message.strip():\n",
    "                annotations = messages.data[0].content[0].text.annotations\n",
    "                quotes = [x.file_citation.quote for x in annotations if x.file_citation]\n",
    "                client.beta.threads.delete(thread.id)\n",
    "                return (response_message, quotes)\n",
    "            time.sleep(1)\n",
    "            max_tries -= 1\n",
    "    except Exception as e:\n",
    "        client.beta.threads.delete(thread.id)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "What key components are necessary to create a technology hub according to Paul Graham?\n",
      "What is the influence of geography on where great cities historically developed, and how has that changed in modern times?\n",
      "How are people classified according to their degree and aggressiveness of conformism?\n",
      "What is the main danger of restricting the discussion of certain ideas?\n",
      "\n",
      "Answers:\n",
      "What key components are necessary to create a technology hub according to Paul Graham?\n",
      "What is the influence of geography on where great cities historically developed, and how has that changed in modern times?\n",
      "How are people classified according to their degree and aggressiveness of conformism?\n",
      "What is the main danger of restricting the discussion of certain ideas?\n"
     ]
    }
   ],
   "source": [
    "# Load questions from qa_pairs.json\n",
    "import json\n",
    "qa_pairs = []\n",
    "with open('qa_pairs.json', 'r') as qa_file:\n",
    "    qa_pairs = json.load(qa_file)\n",
    "\n",
    "question_list = [qa_pair['question'] for qa_pair in qa_pairs]\n",
    "print(\"Questions:\\n\" + \"\\n\".join(question_list[:4]))\n",
    "\n",
    "print()\n",
    "\n",
    "answer_list = [qa_pair['answer'] for qa_pair in qa_pairs]\n",
    "print(\"Answers:\\n\" + \"\\n\".join(question_list[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_calculator = RagScoresCalculator(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    answer_similarity_score=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def count_tokens(text):\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(enc.encode(text))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up assistants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Do not run the following unless you want to delete all files and assistants\n",
    "\n",
    "# def cleanup_files():\n",
    "#     curr_files = list(client.files.list())\n",
    "#     for file in tqdm(curr_files):\n",
    "#         client.files.delete(file.id)\n",
    "\n",
    "# def cleanup_assistants():\n",
    "#     curr_assistants = list(client.beta.assistants.list())\n",
    "#     for curr_assistant in tqdm(curr_assistants):\n",
    "#         client.beta.assistants.delete(curr_assistant.id)\n",
    "\n",
    "# def cleanup_all():\n",
    "#     print(\"Cleaning up files\")\n",
    "#     cleanup_files()\n",
    "#     print(\"Cleaning up assistants\")\n",
    "#     cleanup_assistants()\n",
    "\n",
    "# cleanup_all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI's RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_essays(combined_essays):\n",
    "    # Go through all the combined files and upload them to the assistant\n",
    "    files = []\n",
    "    print(\"Uploading files\")\n",
    "    for filename in tqdm(combined_essays):\n",
    "        with open('combined_essays/' + filename, 'rb') as essay_file:\n",
    "            file = client.files.create(\n",
    "                file=essay_file,\n",
    "                purpose='assistants'\n",
    "            )\n",
    "            files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assistant(files):\n",
    "    return client.beta.assistants.create(\n",
    "        name=f\"OpenAI Rag Test {len(files)} Files\",\n",
    "        instructions=(\n",
    "            \"You are a chatbot that answers questions about Paul Graham's essays. \"\n",
    "            \"Use your knowledge base to best respond to questions. \"\n",
    "            \"NO MATTER WHAT, DO NOT PULL INFORMATION FROM EXTERNAL KNOWLEDGE. ONLY USE YOUR OWN KNOWLEDGE BASE.\"\n",
    "        ),\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        tools=[{\"type\": \"retrieval\"}],\n",
    "        file_ids=[file.id for file in files]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_assistant(file_count):\n",
    "    combined_essays = combine_essays(file_count)\n",
    "    files = upload_essays(combined_essays)\n",
    "    return create_assistant(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function if you want to view the tokens for each file\n",
    "def show_file_token_count(essays):\n",
    "    # Go through all files in combined_essays and then calculate the tokens for each file\n",
    "    total_tokens = 0\n",
    "    count = 0\n",
    "    end_of_selected_files = False\n",
    "    for filename in essays:\n",
    "        with open('combined_essays/' + filename, 'r') as file:\n",
    "            file_tokens = count_tokens(file.read())\n",
    "            count += 1\n",
    "            total_tokens += file_tokens\n",
    "            if filename not in [file.filename for file in files] and not end_of_selected_files:\n",
    "                print(\"--- END OF SELECTED FILES ---\")\n",
    "                end_of_selected_files = True\n",
    "            print(f\"File {count}: {filename} has {file_tokens} tokens. Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping 212 files into groups of 43 files for a total of 5 groups\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:00<00:00, 5782.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paul_graham_1.txt\n",
      "paul_graham_2.txt\n",
      "paul_graham_3.txt\n",
      "paul_graham_4.txt\n",
      "paul_graham_5.txt\n",
      "Uploading files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "assistant = setup_assistant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"I'm sorry, but I wasn't able to find the specific monthly financial goal for Airbnb to achieve ramen profitability during their time at Y Combinator in the excerpts available from Paul Graham's essays. If there is a specific essay or part of an essay where this information might be found, please let me know, or if you have any other questions about Paul Graham's essays, feel free to ask!\", [])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What was Airbnb's monthly financial goal to achieve ramen profitability during their time at Y Combinator?\"\n",
    "openai_response = get_response(prompt, assistant)\n",
    "print(openai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_responses, openai_context = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Go through all questions and get responses from openai assistant\n",
    "for question in tqdm(question_list[len(openai_responses):]):\n",
    "    # If there is an exception, try again until we reach 3 tries at max\n",
    "    max_tries = 3\n",
    "    while True:\n",
    "        try:\n",
    "            openai_response = get_response(question, assistant)\n",
    "            openai_responses.append(openai_response[0])\n",
    "            openai_context.append(openai_response[1])\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            max_tries -= 1\n",
    "            if max_tries == 0:\n",
    "                raise e\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_batch_scores = score_calculator.score_batch(\n",
    "    question_list=question_list [:len(openai_responses)],\n",
    "    reference_answer_list=answer_list[:len(openai_responses)],\n",
    "    llm_answer_list=openai_responses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_test(file_count):\n",
    "    assistant = setup_assistant(file_count)\n",
    "    openai_responses, openai_context = [], []\n",
    "\n",
    "    def get_openai_response(question):\n",
    "        max_tries = 10\n",
    "        while True:\n",
    "            try:\n",
    "                response, context = get_response(question, assistant)\n",
    "                return response, context\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                max_tries -= 1\n",
    "                if max_tries == 0:\n",
    "                    raise e\n",
    "                continue\n",
    "    \n",
    "    # Using ThreadPoolExecutor to process questions in parallel\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Map the process_question function to each question in the list\n",
    "        results = list(tqdm(executor.map(get_openai_response, question_list), total=len(question_list)))\n",
    "    \n",
    "    openai_responses, openai_context = zip(*results)\n",
    "\n",
    "    return score_calculator.score_batch(\n",
    "        question_list=question_list,\n",
    "        reference_answer_list=answer_list,\n",
    "        llm_answer_list=openai_responses,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping 212 files into groups of 212 files for a total of 1 groups\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 212/212 [00:00<00:00, 1492.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paul_graham_1.txt\n",
      "Uploading files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      " 38%|███▊      | 21/55 [00:43<01:13,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404 - {'error': {'message': \"No thread found with id 'thread_1Fy2TaSnMls6MGgFtTHsgoDp'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [04:05<00:00,  4.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# If we are doing a single document, the reliability is increased enough that we can multithread\n",
    "# openai_batch_scores = run_full_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.163636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.182647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       answer_similarity_score\n",
       "count                55.000000\n",
       "mean                  4.163636\n",
       "std                   1.182647\n",
       "min                   1.000000\n",
       "25%                   4.000000\n",
       "50%                   5.000000\n",
       "75%                   5.000000\n",
       "max                   5.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_scores_df = openai_batch_scores.to_dataframe()\n",
    "# Remove overall_score column since we are only using one stat\n",
    "openai_scores_df = openai_scores_df.drop(columns=['overall_score'])\n",
    "openai_scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "category_counts = openai_scores_df['answer_similarity_score'].value_counts()\n",
    "plt.bar(category_counts.index, category_counts.values)\n",
    "\n",
    "plt.title('Distribution of scores for 5 documents')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
