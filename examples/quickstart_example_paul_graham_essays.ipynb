{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e394b",
   "metadata": {},
   "source": [
    "# Llama Index Quick Start Example\n",
    "\n",
    "In the spirit of [Llama Index's starter tutorial](https://gpt-index.readthedocs.io/en/stable/getting_started/starter_example.html) and Andrej Karpathy's [Unreasonable Effectiveness of RNNs blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), we start with an example of a RAG system where the document set consists of Paul Graham essays. (Footnote: The Paul Graham essay text files used were derived from the dataset of Paul Graham essays found in [paul-graham-gpt](https://github.com/mckaywrigley/paul-graham-gpt) github projectl\n",
    "\n",
    "In this notebook, we set up a simple RAG system using llama index, and evaluate the RAG system using 10 predetermined questions and answers about Paul Graham essays. The Paul Graham essays that make up the document set are the 6 essays that have the word founder in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07786f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# llama index imports\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "# tval imports\n",
    "from tval import RagScoresCalculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3ee69",
   "metadata": {},
   "source": [
    "Set up a simple llama index RAG system that uses the default LlamaIndex parameters. The default LlamaIndex parameters use Open AIs ada-002 embedding model as the embedder and gpt-3.5-turbo as the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c362a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./paul_graham_essays\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f08b09",
   "metadata": {},
   "source": [
    "Load 10 questions and answers about the Paul Graham essays as a benchmark for how the RAG system should answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b34a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"question_and_answer_list.json\", \"r\") as f:\n",
    "    question_and_answer_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79df11d",
   "metadata": {},
   "source": [
    "Let's inspect an example, question, answer from the RAG system and reference answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfedbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_q_and_a = question_and_answer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce814d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What makes Sam Altman a good founder?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_q_and_a[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b57275",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(ex_q_and_a[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eee554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam Altman is considered a good founder because he possesses qualities that are highly valued in the startup world. He is known for his determination and force of will, which are crucial for overcoming obstacles and staying motivated in the face of challenges. Altman is also known for his strategic thinking and ambition, making him a valuable resource for startups seeking advice on strategy and ambition. Additionally, Altman's ability to think outside the box and come up with innovative ideas sets him apart as a founder. Overall, Altman's combination of determination, strategic thinking, and creativity make him a highly regarded founder in the startup community.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac98a094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He has a great force of will.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_q_and_a[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a255c6",
   "metadata": {},
   "source": [
    "Set up the score calculator from Tonic Validate. ScoreCalculator will calculate **answer similarity score**, **retrieval precision**, **augmentation precision**, **augmentation accuracy**, **answer consistency**, and the **overall score**.\n",
    "\n",
    "Get the score about the example question and answer about Sam Altman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b585568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use gpt-4 or gpt-3.5-turbo\n",
    "llm_evaluator = \"gpt-4\"\n",
    "# llm_evaluator = \"gpt-3.5-turbo\"\n",
    "score_calculator = RagScoresCalculator(llm_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24c1b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = ex_q_and_a[\"question\"]\n",
    "reference_answer = ex_q_and_a[\"answer\"]\n",
    "llm_answer = response.response\n",
    "context_list = [source_node.node.text for source_node in response.source_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33cefcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_object = score_calculator.score(question, reference_answer, llm_answer, context_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181891f4",
   "metadata": {},
   "source": [
    "`scores_object` is a dataclass object with the scores and the inputs to the `score_calculator.score`. The scores that are not calculated are recorded as `None`. To see just the numeric scores use `scores_to_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e11be5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_similarity_score': [5.0],\n",
       " 'retrieval_precision': [1.0],\n",
       " 'augmentation_precision': [1.0],\n",
       " 'augmentation_accuracy': [1.0],\n",
       " 'answer_consistency_binary': [None],\n",
       " 'answer_consistency': [1.0],\n",
       " 'retrieval_k_recall': [None],\n",
       " 'overall_score': [1.0]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_object.scores_to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925bfe1",
   "metadata": {},
   "source": [
    "We can see the inputs to `score_calculator.score` and the output scores by using `to_dataframe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d0a51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>answer_similarity_score</th>\n",
       "      <th>retrieval_precision</th>\n",
       "      <th>augmentation_precision</th>\n",
       "      <th>augmentation_accuracy</th>\n",
       "      <th>answer_consistency</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What makes Sam Altman a good founder?</td>\n",
       "      <td>He has a great force of will.</td>\n",
       "      <td>Sam Altman is considered a good founder becaus...</td>\n",
       "      <td>[Five Founders\\n\\nApril 2009\\n\\nInc recently a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question               reference_answer  \\\n",
       "0  What makes Sam Altman a good founder?  He has a great force of will.   \n",
       "\n",
       "                                          llm_answer  \\\n",
       "0  Sam Altman is considered a good founder becaus...   \n",
       "\n",
       "                                   retrieved_context  answer_similarity_score  \\\n",
       "0  [Five Founders\\n\\nApril 2009\\n\\nInc recently a...                      5.0   \n",
       "\n",
       "   retrieval_precision  augmentation_precision  augmentation_accuracy  \\\n",
       "0                  1.0                     1.0                    1.0   \n",
       "\n",
       "   answer_consistency  overall_score  \n",
       "0                 1.0            1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_object.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6cf6a",
   "metadata": {},
   "source": [
    "We can specify which scores we would like to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfbde649",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_calculator = RagScoresCalculator(\n",
    "    model=llm_evaluator,\n",
    "    retrieval_precision=True,\n",
    "    augmentation_precision=True,\n",
    "    augmentation_accuracy=True,\n",
    "    answer_consistency=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e8213",
   "metadata": {},
   "source": [
    "None of retrieval precision, augmentation precision, augmentation accuracy, or answer consistency use the reference answer, so we do not need to give that parameter to `score_calculator.score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d8dfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_object = score_calculator.score(\n",
    "    question=question,\n",
    "    llm_answer=llm_answer,\n",
    "    retrieved_context_list=context_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46743702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_similarity_score': [None],\n",
       " 'retrieval_precision': [1.0],\n",
       " 'augmentation_precision': [1.0],\n",
       " 'augmentation_accuracy': [1.0],\n",
       " 'answer_consistency_binary': [None],\n",
       " 'answer_consistency': [1.0],\n",
       " 'retrieval_k_recall': [None],\n",
       " 'overall_score': [1.0]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_object.scores_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df1043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>retrieval_precision</th>\n",
       "      <th>augmentation_precision</th>\n",
       "      <th>augmentation_accuracy</th>\n",
       "      <th>answer_consistency</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What makes Sam Altman a good founder?</td>\n",
       "      <td>Sam Altman is considered a good founder becaus...</td>\n",
       "      <td>[Five Founders\\n\\nApril 2009\\n\\nInc recently a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question  \\\n",
       "0  What makes Sam Altman a good founder?   \n",
       "\n",
       "                                          llm_answer  \\\n",
       "0  Sam Altman is considered a good founder becaus...   \n",
       "\n",
       "                                   retrieved_context  retrieval_precision  \\\n",
       "0  [Five Founders\\n\\nApril 2009\\n\\nInc recently a...                  1.0   \n",
       "\n",
       "   augmentation_precision  augmentation_accuracy  answer_consistency  \\\n",
       "0                     1.0                    1.0                 1.0   \n",
       "\n",
       "   overall_score  \n",
       "0            1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_object.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894c568",
   "metadata": {},
   "source": [
    "Answer all 10 questions and then get the batch score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d48a4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_calculator = RagScoresCalculator(llm_evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d8ca4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for q_and_a in question_and_answer_list:\n",
    "    response = query_engine.query(q_and_a[\"question\"])\n",
    "    q_and_a[\"llm_answer\"] = response.response\n",
    "    q_and_a[\"context_list\"] = [source_node.node.text for source_node in response.source_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa1d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = [q_and_a[\"question\"] for q_and_a in question_and_answer_list]\n",
    "reference_answer_list = [q_and_a[\"answer\"] for q_and_a in question_and_answer_list]\n",
    "llm_answer_list = [q_and_a[\"llm_answer\"] for q_and_a in question_and_answer_list]\n",
    "context_list_list = [q_and_a[\"context_list\"] for q_and_a in question_and_answer_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad37e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_scores = score_calculator.score_batch(\n",
    "    question_list,\n",
    "    reference_answer_list,\n",
    "    llm_answer_list,\n",
    "    context_list_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae29114",
   "metadata": {},
   "source": [
    "The `mean_scores()` method scores calculates the mean of each score over the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f78c1283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_similarity_score': 4.4,\n",
       " 'retrieval_precision': 0.6,\n",
       " 'augmentation_precision': 0.8,\n",
       " 'augmentation_accuracy': 0.55,\n",
       " 'answer_consistency_binary': None,\n",
       " 'answer_consistency': 1.0,\n",
       " 'retrieval_k_recall': None,\n",
       " 'overall_score': 0.766}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_scores.mean_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c6bbc",
   "metadata": {},
   "source": [
    "To inspect the batch scores individually, we can put them into a dataframe that includes in addition to the scoires, the question, reference answer, LLM answer, and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f62a4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = batch_scores.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8adaa543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>retrieved_context</th>\n",
       "      <th>answer_similarity_score</th>\n",
       "      <th>retrieval_precision</th>\n",
       "      <th>augmentation_precision</th>\n",
       "      <th>augmentation_accuracy</th>\n",
       "      <th>answer_consistency</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What makes Sam Altman a good founder?</td>\n",
       "      <td>He has a great force of will.</td>\n",
       "      <td>Sam Altman is considered a good founder becaus...</td>\n",
       "      <td>[Five Founders\\n\\nApril 2009\\n\\nInc recently a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When was the essay \"Five Founders\" written?</td>\n",
       "      <td>April 2009</td>\n",
       "      <td>The essay \"Five Founders\" was written in April...</td>\n",
       "      <td>[Five Founders\\n\\nApril 2009\\n\\nInc recently a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When does the most dramatic growth happen for ...</td>\n",
       "      <td>When the startup only has three or four people.</td>\n",
       "      <td>The most dramatic growth for a startup typical...</td>\n",
       "      <td>[Learning from Founders\\n\\nJanuary 2007\\n\\n(Fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the problem with business culture vers...</td>\n",
       "      <td>In business culture, energy is expended on out...</td>\n",
       "      <td>The problem with business culture versus start...</td>\n",
       "      <td>[Learning from Founders\\n\\nJanuary 2007\\n\\n(Fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's the single biggest thing the government...</td>\n",
       "      <td>Establish a new class of visa for startup foun...</td>\n",
       "      <td>The single biggest thing the government could ...</td>\n",
       "      <td>[The Founder Visa\\n\\nApril 2009\\n\\nI usually a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0              What makes Sam Altman a good founder?   \n",
       "1        When was the essay \"Five Founders\" written?   \n",
       "2  When does the most dramatic growth happen for ...   \n",
       "3  What is the problem with business culture vers...   \n",
       "4  What's the single biggest thing the government...   \n",
       "\n",
       "                                    reference_answer  \\\n",
       "0                      He has a great force of will.   \n",
       "1                                         April 2009   \n",
       "2    When the startup only has three or four people.   \n",
       "3  In business culture, energy is expended on out...   \n",
       "4  Establish a new class of visa for startup foun...   \n",
       "\n",
       "                                          llm_answer  \\\n",
       "0  Sam Altman is considered a good founder becaus...   \n",
       "1  The essay \"Five Founders\" was written in April...   \n",
       "2  The most dramatic growth for a startup typical...   \n",
       "3  The problem with business culture versus start...   \n",
       "4  The single biggest thing the government could ...   \n",
       "\n",
       "                                   retrieved_context  answer_similarity_score  \\\n",
       "0  [Five Founders\\n\\nApril 2009\\n\\nInc recently a...                      4.0   \n",
       "1  [Five Founders\\n\\nApril 2009\\n\\nInc recently a...                      5.0   \n",
       "2  [Learning from Founders\\n\\nJanuary 2007\\n\\n(Fo...                      5.0   \n",
       "3  [Learning from Founders\\n\\nJanuary 2007\\n\\n(Fo...                      5.0   \n",
       "4  [The Founder Visa\\n\\nApril 2009\\n\\nI usually a...                      5.0   \n",
       "\n",
       "   retrieval_precision  augmentation_precision  augmentation_accuracy  \\\n",
       "0                  1.0                     1.0                    1.0   \n",
       "1                  0.5                     1.0                    0.5   \n",
       "2                  0.5                     1.0                    0.5   \n",
       "3                  1.0                     0.5                    0.5   \n",
       "4                  0.5                     1.0                    0.5   \n",
       "\n",
       "   answer_consistency  overall_score  \n",
       "0                 1.0           0.96  \n",
       "1                 1.0           0.80  \n",
       "2                 1.0           0.80  \n",
       "3                 1.0           0.80  \n",
       "4                 1.0           0.80  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e264575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
