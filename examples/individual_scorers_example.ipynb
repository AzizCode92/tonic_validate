{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35db3f2d",
   "metadata": {},
   "source": [
    "# Individual Scorers Example\n",
    "\n",
    "In this notebook, we show how to use each of the scorers in `tval.scorers`.\n",
    "\n",
    "First we set up a RAG system using llama index on our 6 founders Paul Graham essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07786f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./paul_graham_essays\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60795f9",
   "metadata": {},
   "source": [
    "Have a simple sample question and reference answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c362a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What makes Sam Altman a good founder?\"\n",
    "reference_answer = \"He has a great force of will.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a088c",
   "metadata": {},
   "source": [
    "Get the response and retrieved context from the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48024bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a9c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam Altman is considered a good founder because he possesses qualities that are highly valued in the startup world. He is known for his determination and force of will, which are crucial traits for overcoming obstacles and not getting demoralized easily. Altman is also known for his strategic thinking and ambition, which make him a valuable advisor for startups. Additionally, Altman has a strong sense of imagination, allowing him to come up with surprising and innovative ideas. Finally, Altman's ability to build strong relationships and work well with others, such as his close friendship with Emmett Shear, demonstrates his ability to collaborate effectively and create a positive working environment.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6303514",
   "metadata": {},
   "source": [
    "Load the answer and retrieved context into the variables `llm_answer` and `context_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de132f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_answer = response.response\n",
    "retrieved_context_list = [x.node.text for x in response.source_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f1fee",
   "metadata": {},
   "source": [
    "### Answer Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b585568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import AnswerSimilarityScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = AnswerSimilarityScorer(llm_evaluator)\n",
    "\n",
    "similarity_score = scorer.score(question, reference_answer, llm_answer) # score is a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd677b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726121a",
   "metadata": {},
   "source": [
    "### Retrieval Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "901769b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import RetrievalPrecisionScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = RetrievalPrecisionScorer(llm_evaluator)\n",
    "\n",
    "retrieval_precision_score = scorer.score(question, retrieved_context_list) \n",
    "\n",
    "score = retrieval_precision_score.score\n",
    "context_relevant_list = retrieval_precision_score.context_relevant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2587bae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92cb2cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_relevant_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47ffd0",
   "metadata": {},
   "source": [
    "### Augmentation Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6de15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import AugmentationPrecisionScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = AugmentationPrecisionScorer(llm_evaluator)\n",
    "\n",
    "# AugmentationPrecisionScore object\n",
    "augmentation_precision_score = scorer.score(question, llm_answer, retrieved_context_list)\n",
    "\n",
    "# float between 0 and 1\n",
    "score = augmentation_precision_score.score\n",
    "\n",
    "# list of bools of whether each context in retrieved_context_list is relevant\n",
    "context_relevant_list = augmentation_precision_score.context_relevant_list\n",
    "\n",
    "# list of bools of whether each context in context_relevant_list appears in llm_answer\n",
    "answer_contains_context_list = augmentation_precision_score.answer_contains_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628249fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e67f3ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_relevant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "818f7c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_contains_context_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81edee6e",
   "metadata": {},
   "source": [
    "### Augmentation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fed4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import AugmentationAccuracyScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = AugmentationAccuracyScorer(llm_evaluator)\n",
    "\n",
    "# AugmentationAccuracyScore object\n",
    "augmentation_accuracy_score = scorer.score(llm_answer, retrieved_context_list)\n",
    "\n",
    "# float between 0 and 1\n",
    "score = augmentation_accuracy_score.score\n",
    "\n",
    "# list of bools of whether content from each context in retrieved_content_list appears in the answer\n",
    "answer_contains_context_list = augmentation_accuracy_score.answer_contains_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ecb493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_contains_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ff5f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12311d4b",
   "metadata": {},
   "source": [
    "### Answer Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "828ca19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import AnswerConsistencyScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = AnswerConsistencyScorer(llm_evaluator)\n",
    "\n",
    "# AnswerConsistencyScore object\n",
    "answer_consistency_score = scorer.score(llm_answer, retrieved_context_list)\n",
    "\n",
    "# float between 0 and 1\n",
    "score = answer_consistency_score.score\n",
    "\n",
    "# list of main points in the answer\n",
    "main_point_list = answer_consistency_score.main_point_list\n",
    "\n",
    "# list of bools of whether each main point is derived from the context\n",
    "main_point_derived_from_context_list = answer_consistency_score.main_point_derived_from_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd3de0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5294240d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sam Altman is considered a good founder because he possesses qualities that are highly valued in the startup world.',\n",
       " 'He is known for his determination and force of will, which are crucial traits for overcoming obstacles and not getting demoralized easily.',\n",
       " 'Altman is also known for his strategic thinking and ambition, which make him a valuable advisor for startups.',\n",
       " 'Additionally, Altman has a strong sense of imagination, allowing him to come up with surprising and innovative ideas.',\n",
       " \"Finally, Altman's ability to build strong relationships and work well with others, such as his close friendship with Emmett Shear, demonstrates his ability to collaborate effectively and create a positive working environment.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea4bf66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_point_derived_from_context_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953143c",
   "metadata": {},
   "source": [
    "### Answer Consistency Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed23e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import AnswerConsistencyBinaryScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = AnswerConsistencyBinaryScorer(llm_evaluator)\n",
    "\n",
    "# binary integer\n",
    "score = scorer.score(llm_answer, retrieved_context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98216a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2151e87",
   "metadata": {},
   "source": [
    "### Retrieval k-Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acffc8f",
   "metadata": {},
   "source": [
    "For retrieval k-recall, we set up a new RAG system where we make the retriever explicit, so that we can retrieve the top k context. We do k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f036d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.indices.query.schema import QueryBundle\n",
    "\n",
    "# retrieval k-recall with k = 5\n",
    "k = 5\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./paul_graham_essays\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "rag_retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=2\n",
    ")\n",
    "top_k_retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=k\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=rag_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dac485",
   "metadata": {},
   "source": [
    "Get the answer, retrieved context, and top k context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce42d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(question)\n",
    "\n",
    "answer = response.metadata\n",
    "\n",
    "retrieved_context_list = [x.node.text for x in response.source_nodes]\n",
    "\n",
    "query_bundle = QueryBundle(question)\n",
    "top_k_nodes = top_k_retriever.retrieve(query_bundle)\n",
    "top_k_retrieved_context_list = [x.node.text for x in top_k_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b42cde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tval.scorers import RetrievalKRecallScorer\n",
    "\n",
    "llm_evaluator = \"gpt-4\"\n",
    "scorer = RetrievalKRecallScorer(llm_evaluator)\n",
    "\n",
    "score = scorer.score(\n",
    "    question, retrieved_context_list, top_k_retrieved_context_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3badc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "123daf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, False, False]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.top_k_context_relevant_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b6a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
